{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"registration.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MQVZ3Y4vil6e","executionInfo":{"status":"ok","timestamp":1621241858024,"user_tz":-120,"elapsed":120718,"user":{"displayName":"Nohayla Ajmi","photoUrl":"","userId":"01467920580813618471"}},"outputId":"3917d8ff-2d57-40d1-8116-709690002468"},"source":["from google.colab import drive\n","ROOT = \"/content/drive\"  \n","drive.mount(ROOT)  \n","%cd \"/content/drive/MyDrive/PFE_PIMM/\"\n","%ls"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n","/content/drive/MyDrive/PFE_PIMM\n","'Copie de labeling.ipynb'   \u001b[0m\u001b[01;34mmeltpool_bitmap\u001b[0m/     visualisation.ipynb\n"," \u001b[01;34mct_scan\u001b[0m/                   registration.ipynb\n"," labeling.ipynb             \u001b[01;34mtomo_labels\u001b[0m/\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DZfY2xK2pLTG"},"source":["from google.colab.patches import cv2_imshow"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6EI9GM0Ak5aW"},"source":["from __future__ import print_function\n","import cv2\n","import numpy as np\n","import matplotlib.pyplot as plt\n","from os import listdir\n","from fnmatch import fnmatch\n","from IPython.display import clear_output\n","\n","MAX_FEATURES = 500\n","GOOD_MATCH_PERCENT = 0.1\n","\n","def create_circular_mask(h, w, center=None, radius=None):\n","\n","    if center is None: # use the middle of the image\n","        center = (int(w/2), int(h/2))\n","    if radius is None: # use the smallest distance between the center and image walls\n","        radius = min(center[0], center[1], w-center[0], h-center[1])\n","\n","    Y, X = np.ogrid[:h, :w]\n","    dist_from_center = np.sqrt((X - center[0])**2 + (Y-center[1])**2)\n","\n","    mask = dist_from_center <= radius\n","    return mask\n","\n","def clean_vid_image(img):\n","    \n","    h, w = img.shape[:2]\n","    radius = h/4\n","    mask = create_circular_mask(h, w, radius=radius)\n","    masked_img = img.copy()\n","    masked_img[~mask] = 0\n","    return masked_img\n","\n","def crop_vid_image(img):\n","    \n","    h, w = img.shape[:2]\n","    radius = h/2\n","    mask = create_circular_mask(h, w, radius=radius)\n","    masked_img = img.copy()\n","    cropped_img = img[np.ix_(mask.any(1), mask.any(0))]\n","    return cropped_img\n","\n","def get_value_vid_image(img):\n","  i, j = np.where(img != 0)   # find indices where it is nonzero \n","  value = img[i, j]           # extract nonzero values of the array\n","  return value\n","\n","def alignImages(im1, im2,gray=True):\n","\n","  # Convert images to grayscale\n","  if gray :\n","    im1Gray = cv2.cvtColor(im1, cv2.COLOR_BGR2GRAY)\n","    im2Gray = cv2.cvtColor(im2, cv2.COLOR_BGR2GRAY)\n","  else :\n","    im1Gray = im1\n","    im2Gray = im2\n","\n","  im1Gray = clean_vid_image(im1Gray)\n","\n","  im1Gray = cv2.medianBlur(im1Gray,3)\n","  im2Gray = cv2.medianBlur(im2Gray,3)\n","\n","  _,im1Gray = cv2.threshold(im1Gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","  _,im2Gray = cv2.threshold(im2Gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)\n","\n"," \n","  # Detect ORB features and compute descriptors.\n","  orb = cv2.ORB_create(MAX_FEATURES)\n","  keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n","  keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n","\n","  # Match features.\n","  matcher = cv2.DescriptorMatcher_create(cv2.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n","  matches = matcher.match(descriptors1, descriptors2)\n","\n","  # Sort matches by score\n","  matches.sort(key=lambda x: x.distance, reverse=False)\n","\n","  # Remove not so good matches\n","  numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n","  matches = matches[:numGoodMatches]\n","\n","  # Draw top matches\n","  imMatches = cv2.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n","  cv2.imwrite(\"matches.jpg\", imMatches)\n","\n","  # Extract location of good matches\n","  points1 = np.zeros((len(matches), 2), dtype=np.float32)\n","  points2 = np.zeros((len(matches), 2), dtype=np.float32)\n","\n","  for i, match in enumerate(matches):\n","    points1[i, :] = keypoints1[match.queryIdx].pt\n","    points2[i, :] = keypoints2[match.trainIdx].pt\n","\n","  \n","  # Find homography\n","  h, mask = cv2.findHomography(points1, points2, cv2.RANSAC)\n","\n","  # Use homography\n","  height, width, channels = im2.shape\n","  im1Reg = cv2.warpPerspective(im1, h, (width, height))\n","\n","\n","  return im1Reg, h\n","\n","def printProgressBar(iteration, total, prefix='', suffix='', decimals=1, length=100, fill='█', printEnd=\"\\r\"):\n","    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n","    filledLength = int(length * iteration // total)\n","    bar = fill * filledLength + '-' * (length - filledLength)\n","    print(f'\\r{prefix} |{bar}| {percent}% {suffix}')\n","    # Print New Line on Complete\n","    if iteration == total:\n","        print()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3YKr1fA8j3rH"},"source":["cap = cv2.VideoCapture('/content/drive/My Drive/PFE_PIMM/meltpool_bitmap/Piece 1.mp4')\n","\n","while(True):\n","    # Capture frame-by-frame\n","    ret, frame = cap.read()\n","\n","    # Our operations on the frame come here\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    clean = clean_vid_image(gray)\n","\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# When everything done, release the capture\n","cap.release()\n","cv2.destroyAllWindows()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"21xVZBgKo7vt"},"source":["scale_bar = cv2.imread('/content/drive/My Drive/PFE_PIMM/meltpool_bitmap/scaleBar.png')\n","gray = cv2.cvtColor(scale_bar, cv2.COLOR_BGR2GRAY)\n","max = np.amax(gray)\n","min = np.amin(gray)\n","\n","def map_scale(x, in_min=189, in_max=58, out_min=-0.15, out_max=1.33):\n","  return ((out_max - out_min)/(float(in_max) - float(in_min)))*(float(x) - float(in_max)) + out_max\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"P1xjoHXinTyp","executionInfo":{"status":"ok","timestamp":1621253027312,"user_tz":-120,"elapsed":406,"user":{"displayName":"Nohayla Ajmi","photoUrl":"","userId":"01467920580813618471"}},"outputId":"19d10bc1-babe-4f73-9831-e38854d28543"},"source":["frame = cv2.imread('/content/drive/My Drive/PFE_PIMM/meltpool_bitmap/slice_part3.png')\n","\n","gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","cropped = crop_vid_image(gray)\n","\n","value = get_value_vid_image(cropped)\n","\n","print(value.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["(435016,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NfQr64vIsAR2"},"source":["image = cv2.imread('/content/drive/My Drive/PFE_PIMM/meltpool_bitmap/Piece 1.mp4')\n","\n","height, width, channels = image.shape\n","img_binary = np.zeros((height, width, 1))\n","img_grayscale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","\n","ret, thresh = cv2.threshold(img_grayscale, 127, 255, 0)\n","contours, hierarchy = cv2.findContours(thresh, 1, 2)\n","\n","largest_contour_area = 0\n","largest_contour_area_idx = 0\n","\n","for i in range(len(contours)):\n","    if (cv2.contourArea(contours[i]) > largest_contour_area):\n","        largest_contour_area = cv2.contourArea(contours[i])\n","        largest_contour_area_idx = i\n","\n","hull = cv2.convexHull(contours[largest_contour_area_idx])\n","\n","# display results\n","cv2.drawContours(image, [hull], -1, (0, 255, 0))\n","cv2_imshow(image)\n","\n","\n","mask = np.zeros(img.shape, np.uint8)\n","cv2.drawContours(mask, hull, -1, (255),1)\n","locs = np.where(mask == 255)\n","pixels = image[locs]\n","\n","pixels"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"h61eWh2ipTMA"},"source":[""]},{"cell_type":"code","metadata":{"id":"8qGlkT6CqtxQ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617884004271,"user_tz":-60,"elapsed":30773,"user":{"displayName":"KINANI Abdelmoughit","photoUrl":"https://lh5.googleusercontent.com/-w6pID01k_Uk/AAAAAAAAAAI/AAAAAAAAC_c/pJ6Dan-oRrY/s64/photo.jpg","userId":"06026326440239316983"}},"outputId":"912ce93b-d311-4b80-ba96-c81d2820fedd"},"source":["# video to png frames\n","cap= cv2.VideoCapture('/content/drive/My Drive/PFE_PIMM/meltpool_bitmap/Piece 1.mp4')\n","i = 0\n","fps, frames = cap.get(cv2.CAP_PROP_FPS), cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","printProgressBar(0, int(frames), prefix='Extracting frames : ', suffix='Complete', length=50)\n","while(cap.isOpened()):\n","    ret, frame = cap.read()\n","    if ret == False:\n","        break\n","    cv2.imwrite('/content/drive/My Drive/PFE_PIMM/meltpool_bitmap/Frame/frame_'+str(i)+'.png',frame)\n","    clear_output(wait = True)\n","    printProgressBar(i + 1, int(frames), prefix='Extracting frames : ', suffix='Complete', length=50)\n","    i+=1"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rCreating video :  |██████████████████████████████████████████████████| 100.0% Complete\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O6h7z8CPnv_2","executionInfo":{"status":"ok","timestamp":1617884028375,"user_tz":-60,"elapsed":602,"user":{"displayName":"KINANI Abdelmoughit","photoUrl":"https://lh5.googleusercontent.com/-w6pID01k_Uk/AAAAAAAAAAI/AAAAAAAAC_c/pJ6Dan-oRrY/s64/photo.jpg","userId":"06026326440239316983"}},"outputId":"1510f1b5-ea1b-4b8b-924f-3615b962e225"},"source":["# Read reference image\n","refFilename = \"data/feet.png\"\n","print(\"Reading reference image : \", refFilename)\n","imReference = cv2.imread(refFilename, cv2.IMREAD_COLOR)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading reference image :  data/feet.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pFB9olKTqw-M","executionInfo":{"status":"ok","timestamp":1617884029675,"user_tz":-60,"elapsed":681,"user":{"displayName":"KINANI Abdelmoughit","photoUrl":"https://lh5.googleusercontent.com/-w6pID01k_Uk/AAAAAAAAAAI/AAAAAAAAC_c/pJ6Dan-oRrY/s64/photo.jpg","userId":"06026326440239316983"}},"outputId":"3a8bdb52-225c-4eb2-e277-4c0dedc711ff"},"source":["imFilename = \"data/frame_7.png\"\n","print(\"Reading image to align : \", imFilename);\n","im = cv2.imread(imFilename, cv2.IMREAD_COLOR)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Reading image to align :  data/frame_7.png\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SPaM9_2RrT90","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617884031188,"user_tz":-60,"elapsed":858,"user":{"displayName":"KINANI Abdelmoughit","photoUrl":"https://lh5.googleusercontent.com/-w6pID01k_Uk/AAAAAAAAAAI/AAAAAAAAC_c/pJ6Dan-oRrY/s64/photo.jpg","userId":"06026326440239316983"}},"outputId":"dc37a369-f23d-4ef8-8c02-a3be667b9147"},"source":["print(\"Aligning images ...\")\n","# Registered image will be resotred in imReg.\n","# The estimated homography will be stored in h.\n","imReg, h = alignImages(im, imReference,gray=True)\n","# Write aligned image to disk.\n","outFilename = \"aligned.jpg\"\n","print(\"Saving aligned image : \", outFilename);\n","cv2.imwrite(outFilename, imReg)\n","\n","# Print estimated homography\n","print(\"Estimated homography : \\n\",  h)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Aligning images ...\n","Saving aligned image :  aligned.jpg\n","Estimated homography : \n"," [[ 3.56328527e+00  1.17053896e-02 -2.63622206e+03]\n"," [ 7.89312192e-02  3.62951700e+00 -1.47840095e+03]\n"," [ 1.08667357e-04  5.47643424e-05  1.00000000e+00]]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vGAia41TN-Rn"},"source":[""]},{"cell_type":"code","metadata":{"id":"4CxgjHD3QhxH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617884064529,"user_tz":-60,"elapsed":31350,"user":{"displayName":"KINANI Abdelmoughit","photoUrl":"https://lh5.googleusercontent.com/-w6pID01k_Uk/AAAAAAAAAAI/AAAAAAAAC_c/pJ6Dan-oRrY/s64/photo.jpg","userId":"06026326440239316983"}},"outputId":"4b8ffecc-3e69-48fe-95fe-70de867a3b48"},"source":["# APPLYING HOMOGRAPHY TO REST OF FRAMES \n","\n","fourcc = cv2.VideoWriter_fourcc(*'XVID')\n","cap= cv2.VideoCapture('data/Piece 1.mp4')\n","height, width, channels = imReference.shape\n","fps, frames = cap.get(cv2.CAP_PROP_FPS), cap.get(cv2.CAP_PROP_FRAME_COUNT)\n","out = cv2.VideoWriter('result.mp4', fourcc, fps, (width, height))\n","listOfFrames = ['./data/'+x for x in listdir('./data/') if fnmatch(x, \"frame_*\")]\n","printProgressBar(0, len(listOfFrames), prefix='Creating video : ', suffix='Complete', length=50)\n","for index,frame in enumerate(listOfFrames) :\n","    frame = cv2.imread(frame)\n","    im_buffer = cv2.warpPerspective(frame, h, (width, height))\n","    out.write(im_buffer)\n","    clear_output(wait = True)\n","    printProgressBar(index + 1, len(listOfFrames), prefix='Creating video : ', suffix='Complete', length=50)\n","cap.release()\n","out.release()\n","\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\rCreating video :  |██████████████████████████████████████████████████| 100.0% Complete\n","\n"],"name":"stdout"}]}]}